{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f64fd62c-6caa-4631-b8e0-85df58670522",
   "metadata": {},
   "source": [
    "### Zelle 1 — Imports & Reproduzierbarkeit (Seeds)\n",
    "\n",
    "**Was macht diese Zelle?**  \n",
    "Lädt alle Bibliotheken, die wir für Split und Preprocessing brauchen, und setzt einen festen Zufalls-Seed.\n",
    "\n",
    "**Wie funktioniert das?**\n",
    "- `numpy` und `pandas` sind Basiswerkzeuge für numerische Daten und Tabellen.\n",
    "- `train_test_split` (scikit-learn) erzeugt den Train/Test-Split.\n",
    "- `StandardScaler` skaliert numerische Features auf vergleichbare Skalen.\n",
    "- `RANDOM_STATE` + `np.random.seed(...)` sorgen dafür, dass zufällige Prozesse (z. B. Split) reproduzierbar bleiben.\n",
    "\n",
    "**Warum ist das wichtig?**\n",
    "- Ohne Seed bekommst du bei jedem Run andere Splits → andere Ergebnisse → schwer zu debuggen und nicht audit-fähig.\n",
    "- Reproduzierbarkeit ist eine Grundanforderung in ML-Engineering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e262daa-c486-4d83-9d2d-2b3eef53ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZELLE 1 — Imports + Reproduzierbarkeit (Seeds)\n",
    "# Zweck: Einheitliche Ausgangslage für Split/Preprocessing, damit Ergebnisse reproduzierbar sind.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a024734d-589e-4cb5-85cf-5c1393f5c2ae",
   "metadata": {},
   "source": [
    "### Zelle 2 — Daten laden & Basiskontrolle\n",
    "\n",
    "**Was macht diese Zelle?**  \n",
    "Lädt das CSV-Dataset in einen DataFrame und macht eine erste Sichtprüfung.\n",
    "\n",
    "**Wie funktioniert das?**\n",
    "- `pd.read_csv(path)` liest die CSV-Datei ein.\n",
    "- `df.shape` zeigt Zeilen/Spalten und ist der schnellste Plausibilitätscheck.\n",
    "- `df.head()` zeigt die ersten Zeilen, um Spaltennamen und Wertebereiche zu prüfen.\n",
    "\n",
    "**Warum ist das wichtig?**\n",
    "- Frühzeitiges Erkennen von falschen Dateipfaden, falscher Dataset-Version oder Schema-Problemen.\n",
    "- Ohne diesen Check können spätere Schritte „scheinbar“ laufen, aber fachlich auf falschen Daten beruhen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c693e75-8e0d-4db3-a1a2-fe298099aff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (284807, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ZELLE 2 — Daten laden (wie bisher)\n",
    "# Zweck: Rohdaten in DataFrame laden und kurz prüfen.\n",
    "\n",
    "path = \"../data/raw/creditcard.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78425ca9-0d48-4c4d-9fc9-76d233a6ca59",
   "metadata": {},
   "source": [
    "### Zelle 3 — Features (X) und Zielvariable (y) trennen\n",
    "\n",
    "**Was macht diese Zelle?**  \n",
    "Teilt den Datensatz in:\n",
    "- `X`: alle Feature-Spalten (Input fürs Modell)\n",
    "- `y`: die Zielvariable `Class` (Label, das wir vorhersagen wollen)\n",
    "\n",
    "**Wie funktioniert das?**\n",
    "- `df.drop(columns=[target_col])` entfernt die Zielspalte aus X.\n",
    "- `df[target_col]` extrahiert die Labels.\n",
    "- `y.mean()` entspricht bei 0/1-Labels der Fraud-Rate.\n",
    "\n",
    "**Warum ist das wichtig?**\n",
    "- Saubere Trennung verhindert, dass das Modell die Zielvariable direkt „sehen“ kann (Leakage).\n",
    "- Fraud-Rate ist der Kontext für alle späteren Entscheidungen zu Metriken und Thresholds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61eb6e41-f19e-46fb-ab67-12455582da1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (284807, 30)\n",
      "y shape: (284807,)\n",
      "Fraud rate (%): 0.1727\n"
     ]
    }
   ],
   "source": [
    "# ZELLE 3 — Features (X) und Label (y) trennen\n",
    "# Zweck: X enthält nur Features, y enthält nur Zielvariable (Class).\n",
    "\n",
    "target_col = \"Class\"\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Fraud rate (%):\", (y.mean() * 100).round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7dbf37-f6b9-425c-9590-ee5d6446c3c3",
   "metadata": {},
   "source": [
    "### Zelle 4 — Train/Test Split (stratifiziert & deterministisch)\n",
    "\n",
    "**Was macht diese Zelle?**  \n",
    "Teilt die Daten in Trainings- und Testdaten:\n",
    "- Train: Modell darf daraus lernen\n",
    "- Test: bleibt unberührt bis zur finalen Evaluation\n",
    "\n",
    "**Wie funktioniert das?**\n",
    "- `test_size=0.2`: 80/20-Split\n",
    "- `stratify=y`: sorgt dafür, dass der Anteil Fraud in Train und Test ähnlich bleibt\n",
    "- `random_state=RANDOM_STATE`: macht den Split reproduzierbar\n",
    "\n",
    "**Warum ist das wichtig?**\n",
    "- Ohne Stratify kann es passieren, dass im Testset zu wenige Fraud-Fälle landen → Evaluation wird instabil.\n",
    "- Ohne festen Seed sind Ergebnisse nicht reproduzierbar.\n",
    "- Der Testset ist dein „Audit-Check“: Er darf nicht in Entscheidungen einfließen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "714a9686-499f-4611-9600-57a59224dc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (227845, 30)  Test shape: (56962, 30)\n",
      "Train fraud rate (%): 0.1729\n",
      "Test  fraud rate (%): 0.172\n"
     ]
    }
   ],
   "source": [
    "# ZELLE 4 — Train/Test Split (stratifiziert, deterministisch)\n",
    "# Zweck: Testdaten bleiben \"unseen\". Stratify sorgt für ähnlichen Fraud-Anteil in Train/Test.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, \" Test shape:\", X_test.shape)\n",
    "print(\"Train fraud rate (%):\", (y_train.mean() * 100).round(4))\n",
    "print(\"Test  fraud rate (%):\", (y_test.mean() * 100).round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa5e02-04a2-446d-a34b-ec93c058ba9b",
   "metadata": {},
   "source": [
    "### Zelle 5 — Feature-Gruppen definieren (Scaling vs. nicht Scaling)\n",
    "\n",
    "**Was macht diese Zelle?**  \n",
    "Definiert explizit, welche Spalten skaliert werden:\n",
    "- `Time` und `Amount` werden skaliert\n",
    "- `V1–V28` bleiben unverändert\n",
    "\n",
    "**Wie funktioniert das?**\n",
    "- `scale_cols = [\"Time\", \"Amount\"]`\n",
    "- Guard: prüft, ob diese Spalten überhaupt existieren\n",
    "- `other_cols` sammelt alle restlichen Features (meist PCA-Features)\n",
    "\n",
    "**Warum ist das wichtig?**\n",
    "- Tabellarische ML-Pipelines scheitern oft daran, dass Features „blind“ transformiert werden.\n",
    "- Hier machen wir die Entscheidung explizit und nachvollziehbar.\n",
    "- Dadurch bleibt die Pipeline auditierbar: man sieht sofort, was warum skaliert wird.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "842ba6c5-b4db-4771-b703-de7e1d83b566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to scale: ['Time', 'Amount']\n",
      "Other columns count: 28\n"
     ]
    }
   ],
   "source": [
    "# ZELLE 5 — Feature-Gruppen definieren\n",
    "# Zweck: Nur Time und Amount skalieren. V1–V28 bleiben unverändert.\n",
    "\n",
    "scale_cols = [\"Time\", \"Amount\"]\n",
    "\n",
    "# Optionaler Guard: Prüfen, ob die Spalten existieren\n",
    "missing = [c for c in scale_cols if c not in X_train.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing expected columns for scaling: {missing}\")\n",
    "\n",
    "# Alle übrigen Features (PCA-Features + evtl. weitere)\n",
    "other_cols = [c for c in X_train.columns if c not in scale_cols]\n",
    "\n",
    "print(\"Columns to scale:\", scale_cols)\n",
    "print(\"Other columns count:\", len(other_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a7e0e7-47b4-4032-9701-e7acb9f7dc35",
   "metadata": {},
   "source": [
    "### Zelle 6 — Scaling (FIT nur auf Train, TRANSFORM auf Train & Test)\n",
    "\n",
    "**Was macht diese Zelle?**  \n",
    "Skaliert `Time` und `Amount` leakage-sicher.\n",
    "\n",
    "**Wie funktioniert das?**\n",
    "- `scaler.fit(X_train[scale_cols])` lernt Mittelwert und Standardabweichung **nur aus Train**\n",
    "- `scaler.transform(...)` wendet diese Parameter auf Train und Test an\n",
    "- Wir arbeiten auf `.copy()`, damit wir die Originaldaten nicht zerstören\n",
    "\n",
    "**Warum ist das wichtig?**\n",
    "- Wenn du auf Gesamtdata fitten würdest, „kennt“ der Scaler Informationen aus dem Testset → Data Leakage.\n",
    "- Leakage führt fast immer zu zu guten Metriken und falschen Schlussfolgerungen.\n",
    "- Das ist eine der häufigsten Fehlerquellen in ML-Projekten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47910a6a-4461-45d2-95f1-e13ca4d33ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZELLE 6 — Scaler NUR auf Train fitten (Leakage-Schutz)\n",
    "# Zweck: StandardScaler lernt Mittelwert/Std nur aus Train-Daten.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[scale_cols])  # <-- FIT nur auf TRAIN!\n",
    "\n",
    "# Transform auf Train und Test\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[scale_cols] = scaler.transform(X_train[scale_cols])\n",
    "X_test_scaled[scale_cols]  = scaler.transform(X_test[scale_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89520392-39fa-4992-a82c-99082019bfa8",
   "metadata": {},
   "source": [
    "### Zelle 7 — Sanity Checks nach dem Scaling\n",
    "\n",
    "**Was macht diese Zelle?**  \n",
    "Überprüft, ob die Skalierung technisch korrekt war.\n",
    "\n",
    "**Wie funktioniert das?**\n",
    "- Check auf NaNs: Skalierung darf keine fehlenden Werte erzeugen\n",
    "- Statistiken auf `Time` und `Amount`:\n",
    "  - Train: mean ~ 0 und std ~ 1 (weil darauf gefittet wurde)\n",
    "  - Test: nicht zwingend exakt 0/1, aber sinnvoll skaliert\n",
    "\n",
    "**Warum ist das wichtig?**\n",
    "- Ohne Checks merkst du Fehler erst viel später (z. B. wenn Modelle komisch reagieren).\n",
    "- Diese Zelle ist eine technische Qualitätskontrolle der Pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47bc29dd-6bb1-4c82-8b37-09b94ad2beaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X_train_scaled: 0\n",
      "NaNs in X_test_scaled: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>-1.407707e-16</td>\n",
       "      <td>1.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>-2.020811e-17</td>\n",
       "      <td>1.000002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean       std\n",
       "Time   -1.407707e-16  1.000002\n",
       "Amount -2.020811e-17  1.000002"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>-0.007500</td>\n",
       "      <td>0.999960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>0.003456</td>\n",
       "      <td>0.987933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean       std\n",
       "Time   -0.007500  0.999960\n",
       "Amount  0.003456  0.987933"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ZELLE 7 — Quick Sanity Checks nach Scaling\n",
    "# Zweck: Prüfen, ob Scaling korrekt war und keine NaNs entstanden sind.\n",
    "\n",
    "# 1) Keine NaNs\n",
    "print(\"NaNs in X_train_scaled:\", X_train_scaled.isna().sum().sum())\n",
    "print(\"NaNs in X_test_scaled:\", X_test_scaled.isna().sum().sum())\n",
    "\n",
    "# 2) Train: Time/Amount sollten ~0 mean und ~1 std haben (nicht exakt, aber nahe)\n",
    "train_stats = X_train_scaled[scale_cols].agg([\"mean\", \"std\"]).T\n",
    "display(train_stats)\n",
    "\n",
    "# 3) Test: nicht exakt 0/1 (weil mit Train-Parametern transformiert), aber sinnvoll skaliert\n",
    "test_stats = X_test_scaled[scale_cols].agg([\"mean\", \"std\"]).T\n",
    "display(test_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bdffd8-5aa4-4172-8342-53b44f057a08",
   "metadata": {},
   "source": [
    "### Zelle 8 — Final Output der Preprocessing-Stage\n",
    "\n",
    "**Was macht diese Zelle?**  \n",
    "Gibt die finalen, vorverarbeiteten Datensätze aus, die wir ab jetzt überall verwenden.\n",
    "\n",
    "**Wie funktioniert das?**\n",
    "- `X_train_proc` und `X_test_proc` sind die standardisierten Feature-Matrizen\n",
    "- Labels bleiben unverändert: `y_train`, `y_test`\n",
    "- Kurzer Check: Shapes und Fraud-Rates\n",
    "\n",
    "**Warum ist das wichtig?**\n",
    "- Ab jetzt soll kein späterer Schritt mehr auf `df` oder `X_train_scaled` herumarbeiten.\n",
    "- Einheitliche, stabile Variablennamen reduzieren Fehler und machen den Workflow klar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63ea51d5-9f98-47db-8bea-d3b7b2a4321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_proc shape: (227845, 30)\n",
      "X_test_proc shape: (56962, 30)\n",
      "y_train fraud rate (%): 0.1729\n",
      "y_test  fraud rate (%): 0.172\n"
     ]
    }
   ],
   "source": [
    "# ZELLE 8 — Final Output: Preprocessed Datasets bereitstellen\n",
    "# Zweck: Einheitliche Variablennamen, die wir in Baselines und NN wiederverwenden.\n",
    "\n",
    "X_train_proc = X_train_scaled\n",
    "X_test_proc = X_test_scaled\n",
    "\n",
    "print(\"X_train_proc shape:\", X_train_proc.shape)\n",
    "print(\"X_test_proc shape:\", X_test_proc.shape)\n",
    "print(\"y_train fraud rate (%):\", (y_train.mean() * 100).round(4))\n",
    "print(\"y_test  fraud rate (%):\", (y_test.mean() * 100).round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec6eb3e-3254-4386-982e-4b990977de54",
   "metadata": {},
   "source": [
    "### Zelle 9 — (Optional) Spaltenreihenfolge fixieren\n",
    "\n",
    "**Was macht diese Zelle?**  \n",
    "Stellt sicher, dass Train und Test exakt dieselbe Spaltenreihenfolge haben.\n",
    "\n",
    "**Wie funktioniert das?**\n",
    "- `reindex(sorted(...))` sortiert die Spalten im Trainset deterministisch\n",
    "- Testset wird exakt auf diese Spaltenreihenfolge gebracht\n",
    "- `assert` stellt sicher, dass es wirklich identisch ist\n",
    "\n",
    "**Warum ist das wichtig?**\n",
    "- Manche Modelle (und besonders später Export/Inference) erwarten exakt gleiche Feature-Reihenfolge.\n",
    "- Das ist ein klassischer Engineering-Bug: gleiche Spalten, aber andere Reihenfolge → falsche Predictions.\n",
    "- Diese Zelle macht die Pipeline robust.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61142ed0-37d7-440f-846a-6c6a8a9339c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column order aligned. Feature count: 30\n"
     ]
    }
   ],
   "source": [
    "# ZELLE 9 — (Optional) Reihenfolge der Spalten fixieren (Engineering-Schutz)\n",
    "# Zweck: Sicherstellen, dass Train und Test exakt gleiche Spaltenreihenfolge haben.\n",
    "\n",
    "X_train_proc = X_train_proc.reindex(sorted(X_train_proc.columns), axis=1)\n",
    "X_test_proc  = X_test_proc.reindex(X_train_proc.columns, axis=1)\n",
    "\n",
    "assert list(X_train_proc.columns) == list(X_test_proc.columns)\n",
    "print(\"Column order aligned. Feature count:\", X_train_proc.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655a5b95-0220-49cf-9c3b-10ba8c8e5600",
   "metadata": {},
   "source": [
    "### Zelle 10 — (Optional) Artefakte speichern (Scaler)\n",
    "\n",
    "**Was macht diese Zelle?**  \n",
    "Speichert den train-gefitteten Scaler als Artefakt, damit wir dieselbe Transformation später wiederverwenden können.\n",
    "\n",
    "**Wie funktioniert das?**\n",
    "- `joblib.dump(scaler, \"../models/scaler.pkl\")` speichert das Objekt effizient auf Disk\n",
    "- Das `models/`-Verzeichnis ist bewusst per `.gitignore` ausgeschlossen\n",
    "\n",
    "**Warum ist das wichtig?**\n",
    "- Für echte ML-Systeme musst du Preprocessing bei Training, Evaluation und späterer Inferenz identisch anwenden.\n",
    "- Der Scaler ist Teil des Modells (Pipeline-Artefakt).\n",
    "- Ohne Speichern würdest du beim nächsten Run evtl. andere Parameter lernen, was Vergleiche erschwert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "948bcc24-2578-41b0-a27d-dd1a436964a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved scaler to models/scaler.pkl\n"
     ]
    }
   ],
   "source": [
    "# ZELLE 10 — (Optional) Artefakte speichern (nicht in Git)\n",
    "# Zweck: Scaler später für Evaluation/Explainability/Inference wiederverwenden.\n",
    "# Hinweis: models/ ist per .gitignore ausgeschlossen.\n",
    "\n",
    "import joblib\n",
    "joblib.dump(scaler, \"../models/scaler.pkl\")\n",
    "print(\"Saved scaler to models/scaler.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (secure-ai)",
   "language": "python",
   "name": "secure-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
